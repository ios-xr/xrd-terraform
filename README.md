
# XRd Terraform modules

Terraform modules for running XRd in cloud environments.

Currently this only covers running XRd in an AWS EKS cluster.

This repository is intended to be used for two purposes:
  - As an illustrative example of what's needed to set up XRd in AWS EKS, to
    be read alongside the other XRd documentation.
  - As a simple way to launch a dummy XRd deployment in AWS EKS for
    experimentation and exploration.

Use of these modules in production is not supported by Cisco.

## Requirements

The following CLI tools are required to use the modules and scripts in
this repository:
   1. The [`aws`](https://aws.amazon.com/cli/) tool,
      configured with your account details.
   2. The [`terraform`](https://www.terraform.io/) tool.
   3. The [`helm`](https://helm.sh/) tool.

The [`packer`](https://www.packer.io/) tool is required if you want to
use the quick start script, see the [AMI](#ami) section below for more details.

In addition, the following tools are recommended:
  1. [kubectl](https://kubernetes.io/docs/reference/kubectl/)
  2. At least one of the following tools, for container image handling:
     1. [`docker`](https://www.docker.com/)
     2. [`podman`](https://podman.io/)
     3. [`skopeo`](https://github.com/containers/skopeo)

### AMI

The Terraform modules in this repository rely on the AMIs used for worker
nodes to be optimized for XRd. The easiest way to achieve this is to use the
[XRd Packer](https://github.com/ios-xr/xrd-packer) templates to generate
an AMI suitable for running XRd.

The Terraform module will automatically pick up AMIs generated by this
tool in your AWS account.

N.B. These AMIs are tied to a particular Kubernetes version, so multiple
AMIs may be required if you want to run EKS clusters using multiple
different Kubernetes versions.

The quick start script will build an AMI using this repository for you if
one isn't detected in your AWS account. To run this, the
[`packer`](https://www.packer.io/) tool must also be installed.

## Quick Start

To bring up a dummy XRd deployment in XRd EKS, the following steps are
required:

  1. Create an AWS ECR repository, an upload an XRd container image to it.
     1. First, an XRd vRouter image should be obtained from Cisco.
     2. Then, the `publish-ecr` script in this repository can be used to
        created the repository and upload the image.
     3. Example: `./publish-ecr xrd-vrouter-container-x86.7.9.1.tgz`
  2. Run the `aws-quickstart` script.
     1. This has two mandatory arguments, the username and password to be
        used for the XRd root user.
     2. This will first build an AMI using the
        [XRd Packer](https://github.com/ios-xr/xrd-packer) templates if one
        is not detected.
     3. Example: `./aws-quickstart -u root -p mypassword`

This will bring up an EKS cluster called 'xrd-cluster', some worker nodes,
and a dummy topology with a pair of back-to-back XRd instances running an
overlay network between them - the `overlay` example topology described below.

To interact with the cluster, run:

```
aws eks update-kubeconfig --name xrd-cluster
```

and then interact with the cluster as normal using `kubectl` commands, e.g. to
get to an XRd console you can use:

```
kubectl exec -it xrd1-xrd-vrouter-0 -- xr
```

N.B. In production use-cases it's recommended to set up SSH access to XRd
routers, this is just intended for lab usage.

To tear down all of the resources, run:

```
cd examples/overlay
terraform destroy
rm quickstart.auto.tfvars
```

## Modules

This repository contains several Terraform modules to assist with deploying
XRd on AWS. There are two types of template:

  - "Building block" modules (sometimes called 'resource' modules) - these are
    focussed on a single AWS area or resource, used to build a full
    deployment stack.
  - "Example" modules (sometimes called 'infrastructure' modules) - these use
    the building block modules to bring up an entire example deployment.

### Building Block Modules

The following building block modules are provided in the repository:
 - VPC
 - EKS
 - IRSA
 - EC2 Key Pair
 - Bastion Node
 - Worker Node

Each of these modules is focussed on bringing up a constrained set of
AWS resources. These are used by the example modules describe below, and
generally its expected that only developers will need to use these directly.
As such, more detail for these modules can be found on the
[development](DEVELOPMENT.md) page.

### Example Modules

There are three example modules in the repository:

  - [`singleton`](examples/singleton/README.md), which brings up a cluster
    with a single worker node, and runs a single XRd workload on it.
  - [`overlay`](examples/overlay/README.md),, which brings up a cluster with
    a pair of back-to-back XRd instances running an overlay network using
    GRE, IS-IS and L3VPN; and a pair of linux containers that communicate via
    the overlay network.
  - [`ha`](examples/ha/README.md), which brings up a cluster with a pair of
    XRd instances with associated
    [HA applications](https://github.com/ios-xr/xrd-ha-app) that facilitate
    failover.

## Running Examples

To launch an example, first make sure you have met all the requirements
listed [above](#requirements), including having an AMI suitable for running
the required XRd platform available.

Once you have satisfied the requirements, each example can be launched like
any other Terraform module.

Running the module will take around 20 minutes, most of which is
taken up waiting for the EKS control plane to launch.

Step-by-step instructions for this can be found in the following sections.
More details on all the Terraform command options can be found in the
[Terraform CLI documentation](https://developer.hashicorp.com/terraform/cli).

### Bring-up

Firstly, clone this repository and navigate to the example's directory.

Terraform needs to initialize all the submodules, which can be done by
running:

```
terraform init
```

Once Terraform has initialized, you should check the
[`variables.tf`](variables.tf) file to find all the configuration options for
the example.

Create a file called `vars.tfvars` and set the configuration you want to
use following the
[variable definitions file format](https://developer.hashicorp.com/terraform/language/values/variables#variable-definitions-tfvars-files),
e.g.:

```
cluster_version = 1.26
xr_root_user = "testuser"
xr_root_password = "testpass"
```

Terraform can then be run using the following command:

```
terraform apply -var-file=vars.tfvars
```

Configuration options can also be configured on the CLI, e.g.:

```
terraform apply -var cluster_version=1.26
```

Terraform will show you a changeset and ask you to confirm that it should
proceed. Once you have done so, it will take around 20 minutes to completely
bring up the example.

### Modification

Once the topology has been launched, any changes you make to the configuration
can be applied by modifying the configuration file and re-running the
`terraform apply -var-file=vars.tfvars` command - Terraform will compute the
minimal diff required to satisfy your new configuration and apply it.

### Teardown

When you've finished with the topology, it can be torn down with:

```
terraform destroy -var-file=vars.tfvars
```

N.B. It is recommended to pass the same configuration to `terraform destroy`
as were passed to `terraform apply`: this ensures that any mandatory arguments
are set (even if their values don't matter) and means that any automatic
inference of values is the same (e.g. automatically picking up XRd
Packer AMIs at the correct cluster version, which will fail of no such
image is present even in destroy mode).

## Alternative workflows

### Using Terraform to manage infrastructure only

All the examples in this repository support several configuration
flags that control how much is brought up by Terraform. One of these is
the `create_workload` flag, which is set to `true` by default.

Setting this to `false` for an example template means that all the AWS
infrastructure (e.g. VPC, EKS cluster, worker nodes) will be brought up,
but no XRd workload will be installed into the cluster.

This mode of operation can be useful to users who want to manage the workload
outside of Terraform, e.g. by using Helm directly.

### Flexible lab environments

Users in a lab environment may want to bring up a single set of infrastructure
that allows flexible topologies to be overlaid on top.

Users comfortable with writing Terraform and debugging problems themselves
can look at the [DEVELOPMENT](DEVELOPMENT.md) pages for more details
on templates provided in this repository to help.

## Troubleshooting

This section lists some common errors and how to fix them.

### Invalid AWS Provider Configuration

#### Example Error Message

```
|
│ Error: Invalid provider configuration
│
│ Provider "registry.terraform.io/hashicorp/aws" requires explicit configuration. Add a provider block to the root module and configure the provider's
│ required arguments as described in the provider documentation.
│
╵
╷
│ Error: configuring Terraform AWS Provider: no valid credential sources for Terraform AWS Provider found.
│
│ Please see https://registry.terraform.io/providers/hashicorp/aws
│ for more information about providing credentials.
│
│ AWS Error: failed to refresh cached credentials, no EC2 IMDS role found, operation error ec2imds: GetMetadata, request canceled, context deadline exceeded
│
│
│   with provider["registry.terraform.io/hashicorp/aws"],
│   on <empty> line 0:
│   (source code not available)
```

#### Cause

Your environment is not set up correctly to run AWS CLI commands.

#### Fix

Configure your environment with your AWS account details.
You may need to run `aws configure`, or specify the `AWS_PROFILE` environment
variable.

### AWS AMI requery returned no results

#### Example Error Message

```
╷
│ Error: Your query returned no results. Please change your search criteria and try again.
│
│   with module.xrd_ami[0].data.aws_ami.this,
│   on ../../modules/aws/xrd-ami/main.tf line 12, in data "aws_ami" "this":
│   12: data "aws_ami" "this" {
│
╵
```

#### Cause

There is no available AMI created by the XRd Packer templates with the
requested Kubernetes version.

#### Fix

Either:
  1. Create an AMI at the correct version using the
     [XRd Packer](https://github.com/ios-xr/xrd-packer) templates.
  2. Specify an AMI ID to use for the worker nodes by setting the `node_ami`
     Terraform variable.