
# XRd Terraform modules

Terraform modules for running XRd in cloud environments.

Currently this only covers running XRd in an AWS EKS cluster.

This repository is intended to be used for two purposes:
  - As an illustrative example of what's needed to set up XRd in AWS EKS, to
    be read alongside the other XRd documentation.
  - As a simple way to launch a dummy XRd deployment in AWS EKS for
    experimentation and exploration.

Use of these modules in production is not supported by Cisco.

## Requirements

The following CLI tools are required to use the modules and scripts in
this repository:
   1. The [`aws`](https://aws.amazon.com/cli/) tool,
      configured with your account details.
   2. The [`terraform`](https://www.terraform.io/) tool.
   3. The [`helm`](https://helm.sh/) tool.

The [`packer`](https://www.packer.io/) tool is required if you want to
use the quick start script, see the [AMI](#ami) section below for more details.

In addition, the following tools are recommended:
  1. [kubectl](https://kubernetes.io/docs/reference/kubectl/)
  2. At least one of the following tools, for container image handling:
     1. [`docker`](https://www.docker.com/)
     2. [`podman`](https://podman.io/)
     3. [`skopeo`](https://github.com/containers/skopeo)

### AMI

The Terraform modules in this repository rely on the AMIs used for worker
nodes to be optimized for XRd. The easiest way to achieve this is to use the
[XRd Packer](https://github.com/ios-xr/xrd-packer) templates to generate
an AMI suitable for running XRd.

The Terraform module will automatically pick up AMIs generated by this
tool in your AWS account.

N.B. These AMIs are tied to a particular Kubernetes version, so multiple
AMIs may be required if you want to run EKS clusters using multiple
different Kubernetes versions.

The quick start script will build an AMI using this repository for you if
one isn't detected in your AWS account. To run this, the
[`packer`](https://www.packer.io/) tool must also be installed.

## Quick Start

To bring up a dummy XRd deployment in XRd EKS, the following steps are
required:

  1. Create an AWS ECR repository, an upload an XRd container image to it.
     1. First, an XRd vRouter image should be obtained from Cisco.
     2. Then, the `publish-ecr` script in this repository can be used to
        created the repository and upload the image.
     3. Example: `./publish-ecr xrd-vrouter-container-x86.7.9.1.tgz`
  2. Run the `aws-quickstart` script.
     1. This has two mandatory arguments, the username and password to be
        used for the XRd root user.
     2. This will first build an AMI using the
        [XRd Packer](https://github.com/ios-xr/xrd-packer) templates if one
        is not detected.
     3. Example: `./aws-quickstart -u root -p mypassword`

This will bring up an EKS cluster called 'xrd-cluster', some worker nodes,
and a dummy topology with a pair of back-to-back XRd instances running an
overlay network between them - the `overlay` example topology described below.

To interact with the cluster, run:

```
aws eks update-kubeconfig --name xrd-cluster
```

and then interact with the cluster as normal using `kubectl` commands, e.g. to
get to an XRd console you can use:

```
kubectl exec -it xrd1-xrd-vrouter-0 -- xr
```

N.B. In production use-cases it's recommended to set up SSH access to XRd
routers, this is just intended for lab usage.

To tear down all of the resources, run:

```
./aws-quickstart --destroy
```

## Modules

This repository contains several Terraform modules to assist with deploying
XRd on AWS. There are two types of modules:

  - "Building block" modules (sometimes called 'resource' modules) - these are
    focused on a single AWS area or resource, used to build a full
    deployment stack.
  - "Example" modules (sometimes called 'infrastructure' modules) - these use
    the building block modules, and together can bring up an entire entire
    example deployment.

### Building Block Modules

The following building block modules are provided in the repository:
 - VPC
 - EKS
 - IRSA
 - EC2 Key Pair
 - Bastion Node
 - Worker Node

Each of these modules is focused on bringing up a constrained set of
AWS resources. These are used by the example modules describe below, and
generally its expected that only developers will need to use these directly.
As such, more detail for these modules can be found on the
[development](DEVELOPMENT.md) page.

### Example Configurations

Example Terraform configuration are provided; each of these either creates a
set of cloud infrastructure resources, or a set of workload resources.

Together a stack of example configurations forms a complete and functional set
of resources, representing an example XRd deployment.

#### Bootstrap

The [Bootstrap](/examples/bootstrap/README.md) configuration forms a common
base; other example configurations are layered on top of this base.

#### Singleton

The Singleton example is formed of an [infrastructure
configuration](/examples/singleton/infra/README.md) and a [workload
configuration](/examples/singleton/workload/README.md).

Together this runs an XRd Control Plane, or XRd vRouter workload on a single
worker node.

#### Overlay

Similarly the Overlay example is formed of an [infrastructure
configuration](/examples/overlay/infra/README.md) and a [workload
configuration](/examples/overlay/workload/README.md).

Together this launches three worker nodes, and deploys a pair of back-to-back
XRd vRouter instances running an overlay network using GRE, IS-IS and L3VPN;
and a pair of Linux containers that communicate via the overlay network.

## Running Examples

To launch an example, first make sure you have met all the requirements
listed [above](#requirements), including having an AMI suitable for running
the required XRd platform available.

Once you have satisfied the requirements, each example can be launched like any
any other Terraform configuration.  The Bootstrap configuration serves as a
base for other configurations; an infrastructure configuration should be
layered on top of the Bootstrap configuration, and a workload configuration
should be layered on top of the associated infrastructure configuration.

The following sections walk through instantiating the Overlay example.  More
details on all the Terraform command options can be found in the [Terraform CLI
documentation](https://developer.hashicorp.com/terraform/cli).

### Bring-up

Firstly, clone this repository.

The Bootstrap configuration must be run first; this provisions a VPC, EKS
cluster, and Bastion node (for worker node access).

```
terraform -chdir=examples/bootstrap init
terraform -chdir=examples/bootstrap apply
```

Terraform will show you a changeset and ask you to confirm that it should
proceed.  It takes around 15 minutes to bring up the configuration.

Then apply the Overlay infrastructure configuration.  This creates the
remaining cloud infrastructure resources necessary for running the Overlay
workload.

```
terraform -chdir=examples/overlay/infra init
terraform -chdir=examples/overlay/infra apply
```

Finally apply the Overlay workload configuration.  This accepts a number of
input variables described in
[`variables.tf`](/examples/overlay/workload/variables.tf) which may be of
interest; e.g., it is necessary to set the IOS XR root username and password.
To do so, create a file `vars.tfvars` with the desired configuration options
following the [variable definitions file
format](https://developer.hashicorp.com/terraform/language/values/variables#variable-definitions-tfvars-files).

```
cat << EOF
xr_root_user = "root"
xr_root_password = "mypassword"
EOF > vars.tfvars

terraform -chdir=examples/overlay/workload init
terraform -chdir=examples/overlay/workload apply -var-file=vars.tfvars
```

Configuration options can also be [configured on the
CLI](https://developer.hashicorp.com/terraform/language/values/variables#variables-on-the-command-line).

### Modification

Once the topology has been launched, any changes you make to the configuration
can be applied by modifying the configuration file and re-running the
`terraform -chdir=examples/overlay/workload apply -var-file=vars.tfvars`
command - Terraform will compute the minimal diff required to satisfy your new
configuration and apply it.

### Teardown

When you've finished with the topology, it can be torn down with:

```
terraform -chdir=examples/overlay/workload destroy -var-file=vars.tfvars
terraform -chdir=examples/overlay/infra destroy
terraform -chdir=examples/bootstrap destroy
```

N.B. It is recommended to pass the same configuration to `terraform destroy`
as were passed to `terraform apply`: this ensures that any mandatory arguments
are set (even if their values don't matter) and means that any automatic
inference of values is the same (e.g. automatically picking up XRd
Packer AMIs at the correct cluster version, which will fail of no such
image is present even in destroy mode).

## Troubleshooting

This section lists some common errors and how to fix them.

### Invalid AWS Provider Configuration

#### Example Error Message

```
|
│ Error: Invalid provider configuration
│
│ Provider "registry.terraform.io/hashicorp/aws" requires explicit configuration. Add a provider block to the root module and configure the provider's
│ required arguments as described in the provider documentation.
│
╵
╷
│ Error: configuring Terraform AWS Provider: no valid credential sources for Terraform AWS Provider found.
│
│ Please see https://registry.terraform.io/providers/hashicorp/aws
│ for more information about providing credentials.
│
│ AWS Error: failed to refresh cached credentials, no EC2 IMDS role found, operation error ec2imds: GetMetadata, request canceled, context deadline exceeded
│
│
│   with provider["registry.terraform.io/hashicorp/aws"],
│   on <empty> line 0:
│   (source code not available)
```

#### Cause

Your environment is not set up correctly to run AWS CLI commands.

#### Fix

Configure your environment with your AWS account details.
You may need to run `aws configure`, or specify the `AWS_PROFILE` environment
variable.

### AWS AMI requery returned no results

#### Example Error Message

```
╷
│ Error: Your query returned no results. Please change your search criteria and try again.
│
│   with module.xrd_ami[0].data.aws_ami.this,
│   on ../../modules/aws/xrd-ami/main.tf line 12, in data "aws_ami" "this":
│   12: data "aws_ami" "this" {
│
╵
```

#### Cause

There is no available AMI created by the XRd Packer templates with the
requested Kubernetes version.

#### Fix

Either:
  1. Create an AMI at the correct version using the
     [XRd Packer](https://github.com/ios-xr/xrd-packer) templates.
  2. Specify an AMI ID to use for the worker nodes by setting the `node_ami`
     Terraform variable.
